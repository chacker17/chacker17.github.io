<!DOCTYPE HTML>
<html>
    <head>
        <title>Catrina Hacker</title>
        <link rel="stylesheet" href="./resources/css/research_style.css" type ="text/css"/>
        <link href='https://fonts.googleapis.com/css?family=Mallanna' rel='stylesheet'>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    </head>
    <body>
            <!-- HEADER/LINKS -->
            <header>
                <span id = "name">Catrina M. Hacker</span>
                <nav>
                    <span><a href="index.html">Home</a></span>
                    <span><a href="cv.html">CV</a></span>
                    <span><a href="research.html">Research</a></span>
                    <span><a href="writing.html">Writing</a></span>
                    <span><a href="contact.html">Contact</a></span>
                </nav>
            </header>

            <!-- Visual Memory Lab -->
            <div id  = "pageBody">
                <span id = "lab"><b>Visual Memory Lab, University of Pennsylvania</b></span>
                <div id= "oneLab">

                    <span id = "titleFirst"><b>Comparing visual memory representations in spikes and LFPs</b></span>
                    <div class = "project">

                         <div class = "picture">
                            <img src = "./resources/images/spikesLFPs.png" height="275px">
                        </div>

                        <div class = "description" id = "right">

                            <p>We've learned a lot about the brain by studying the activity of individual neurons, called spikes, in animal brains. However, a different measure of brain activity, called field potentials, is more often measured when recording from the brains of human patients, especially in a clinical context. In order to take what we've learned from studying animal brains and apply it to humans, we need to understand how the neural representations we observe in spikes are related to those in field potentials. To address this, I analyzed a dataset with established spiking representations of visual memory to answer a simple question: would the same inferences about the neural representations supporting memory have been made if measures were limited to field potentials? Across many rigorous tests, the answer is resoundingly (and excitingly) yes when considering high-gamma activity (50-150 Hz) of the field potential. This work suggests that a type of neural representation called a magnitude code is well-positioned for translation across model species. More generally, these results show that high-gamma activity is a robust, sensitive, efficient, and common neural measurement that allows for both reliable translation across scales of measurement and species, supporting translational work.</p>

                            <!-- <p>A central premise of basic neuroscience research is that insights about the healthy brain may eventually inform treatments for neurological and neuropsychiatric disorders. While much of the recent progress in systems neuroscience has relied on densely sampled, high spatial resolution measures of neural activity (like spikes), most neural recordings available in humans are field potentials. Consequently, bridging the divide between animal and human neuroscience requires understanding how neural representations compare in those different types of data. To fill this gap, I analyzed a dataset with established spiking representations of visual memory to answer a simple question: would the same inferences about the neural representations supporting memory have been made if measures were limited to field potentials? Using spike and local field potential (LFP) data simultaneously recorded in inferotemporal cortex (ITC), we examined the neural representations of four stimulus attributes known to influence visual memory: novelty, delay, memorability, and contrast. Using spike and local field potential (LFP) data simultaneously recorded in inferotemporal cortex (ITC), we show that the neural representations of four variables are aligned across spikes and high-gamma activity: novelty, delay, memorability, and contrast. In addition, we show that condition-specific, and in some cases image-specific, neural representations are matched across both measures. Going a step further, we found that memory task performance could be predicted as well from high-gamma activity as from spikes, using the same decoding scheme, but that at least 3-fold more data is required to reach the same decoding level with spikes as with LFPs. Overall, we demonstrate that high-gamma activity in the LFP is sensitive enough to capture neural representations of visual memory as well as spikes, but that the lower data requirements make high-gamma the more efficient option.</p>

                            <p>Our results suggest that magnitude codes (which are abundant across many domains in systems neuroscience, from memroy to mood) are well-positioned for translation across model species. More generally, our results show that high-gamma activity is a robust, sensitive, efficient, and common neural measurement that allows for both reliable translation across scales of measurement and species, supporting translational work.</p> -->
                        </div>

                    </div>

                    <span id = "titleFirst"><b>Identifying the neural correlates of context-dependent changes in image memorability</b></span>
                    <div class = "project">
                        <div class = "description">
                            <p>Humans are really good at remembering what they see, but the same image can become more or less memorable depending on what other things you've recently seen. For example, we're much less likely to remember a particular dog when we've just seen 10 other dogs than we are if we see that same dog after seeing 10 other objects. This type of flexible processing is something that makes our brains more than just a static computer that always produces the same output for a given input. This project asks a simple question: What changes about the neural representation of a given image such that it's better remembered in one context and not another? Answering this question is essential for understanding how visual memory operates in naturalistic contexts where the set of objects we're looking at is constantly changing. Our investigations into this question are ongoing.</p>
                        </div>

                        <div class = "picture" id = "right">
                            <img src = "./resources/images/dogs.png" height="275px">
                        </div>

                    </div>

                </div>

                <!-- BOTTJER SONGBIRD LAB -->
                <span id = "lab"><b>Bottjer Songbird Lab, University of Southern California</b></span>
                <div id = "oneLab">
                    <span id = "titleFirst"><b>Optogenetic Disruption of Song-Learning in Juvenile Zebra Finches</b></span>
                    <div class = "project">
                        <div class = "picture">
                            <img src = "./resources/images/zebraFinches.jpg"/>
                        </div>
                        <div class = "description" id = "right">
                            <p>Juvenile zebra finches are often studied as a model of motor learning because of the remarkable ability of juveniles to learn highly complex and stereotyped songs from a tutor. 
                                Such learning requires the integration of information in cortico-basal ganglia loops carrying motor signals with information in evaluative loops that assess and refine the bird&#8217s song. 
                                Cortical area AId is a compelling site for such integration as the motor and evaluative loops converge in juveniles via a collateral that disappears in adulthood after their song has been learned. 
                                To test whether altering activity in AId can prevent accurate copying of tutor song, I helped develop a paradigm in which the singing of a specific syllable is paired with optogenetic disruption of AId in juveniles. 
                                Work is still being done to determine the impact of these disruptions.</p>
                        </div>
                    </div>
                </div>

                <!-- IMAGE UNDERSTANDING LAB -->
                <span id = "lab"><b>Image Understanding Lab, University of Southern California</b></span>
                <div id = "oneLab">
                    <!-- <span id = "titleFirst"><b>Background Invariance in Face Recognition</b></span>
                    <div class = "project">
                        <div class = "picture">
                            <img src = "./resources/images/backgroundInvariance.png"/>
                        </div>
                        <div class = "description" id = "right">
                            <p>Face recognition benefits greatly from the large receptive fields (r.f.s) in late stages of the ventral visual stream such as the Fusiform Face Area (FFA). 
                                The employment of these r.f.s in face recognition allows for the magnification of the small metric differences that differentiate faces and build the wholistic impression that we experience in natural face recognition. 
                                Despite the use of such large r.f.s, our subjective impression is that face recognition is unaffected by changes to the background, however this has not been rigorously tested. 
                                I worked with Rose Meltzer in the IUL to develop a behavioral task that tests the extent to which face recognition is affected by the presence of a background that is known to activate face-selective areas versus one that is not.</p>
                            <p><a href = "https://www.testable.org/experiment/373/921775/start" target = "_blank">Try the test!</a></p>
                        </div>
                    </div> -->
               
                    
                    <span id = "titleFirst"><b>Assesesing Proficiency for Face Memory Independent of Face Perception</b></span>
                    <div class = "project">
                        <div class = "description">
                            <p>Most tests of face recognition implicitly assume it to be an undifferentiated ability. 
                                However, several independent components could comprise face recognition proficiency, such as those for the perceptual discrimination of faces, face memory and the ability to generalize across viewpoints. 
                                I designed a behavioral task to separate two of these potential components: proficiency for the perceptual discrimination of faces and proficiency for face memory. 
                                Using this task, I found evidence on the group level that these are two independent processes. 
                                My analyses also suggest that these two proficiencies may be uncorrelated on an individual basis, challenging the generally held assumption that face recognition is a general ability that cannot be differentiated into independent components. </p>
                            <p><a href = "./resources/videos/FMT_demo.mp4" target = "_blank">Watch a demo of the task</a> or <a href = "./resources/downloadable_files/Hacker_FMT_Poster_2019.pdf" target = "_blank">check out the poster</a> or <a href = "https://psyarxiv.com/9bwct/" target = "_blank">read the preprint</a>!</p>
                        </div>
                        <div class = "picture" id = "right">
                                <video height = "250" autoplay loop>
                                        <source src = "./resources/videos/FMT_short_cropped.mp4" type="video/mp4">
                                            Your browser does not support this video :(
                                </video>
                        </div>
                    </div>

                    <span id = "title"><b>A Neurocomputational Account of the Difficulty of Recognizing a Face Rotated in Depth</b></span>
                    <div class = "project">
                        <div class = "picture">
                            <video height = "250" autoplay loop>
                                <source src="./resources/videos/OFPT_short_cropped.mp4" type = "video/mp4">
                                    Your browser does not support this video :(
                            </video>
                        </div>
                        <div class = "description" id = "right">
                            <p>
                                Previous studies have demonstrated that recognizing an unfamiilar face rotated in depth is difficult, but have not offered explanations as to why.
                                We quantified the difference in representation imposed by rotating a face using the gabor jet model, and compared this to the representational difference between two test faces. The gabor jet model has previously been shown to correlate strongly with perceptual discrimination of similar faces.
                                We found that two factors were sufficient to account for the difficulty of any given trial: 1) The orientation disparity between the matching and sample images and 2) the similarity between the match and distractor images.
                                With modest rotations of just 13&#176 or 20&#176, we documented a before unappreciated huge difference in representation imposed by rotating a face in depth that could account for the difficulty of this task.
                            </p>
                            <p><a href = "./resources/videos/OFPT_demo_cropped.mp4" target = "_blank">Watch a demo of the task</a> or <a href = "./resources/downloadable_files/Zhu_OFPT_Poster_2019.pdf" target = "_blank">check out the poster</a> or <a href="https://www.sciencedirect.com/science/article/pii/S0042698921002030" target = "_blank">read the paper!</a></p>
                        </div>
                    </div>

                    <span id = "title"><b>Recognition of Stretched Faces</b></span>
                    <div class = "project">
                        <div class = "description">
                            <p>In 2002, Graham Hole showed that we have a remarkable capacity to recognize familiar faces that have been stretched vertically or horizontally by a factor of 2. 
                                Since this discovery, no explanation has been given for this invariance. 
                                One possibility is that familiarity with a face facilitates invariance to stretch similarly to how familiarity has been shown to facilitate invariance to rotation in depth. 
                                To test this, I designed a behavioral task to determine if familiarity with a face could also explain invariance to stretch by having subjects rate their familiarity with a number of celebrities used in the task. 
                                My results show that familiarity cannot account for stretched face recognition. After rejecting the possibility that faces are &#8220un-stretched&#8221 by warping them to an average face we suggest that the percept of an elongated face provides a signal for the shrink-wrapping of receptive fields to conform to an attended object, a phenomenon witnessed in single unit activity in the macaque by Moran and Desimone (1985). 
                                Such a phenomenon may serve, more generally, as the underlying neural mechanism for object-based attention. </p>
                            <p><a href = "./resources/videos/SF_demo.mp4" target = "_blank">Watch a demo of the task</a> or <a href = "./resources/downloadable_files/StretchedFaces_VSS_18.pdf" target = "_blank">check out the poster</a> or <a href = "https://psyarxiv.com/e5hgx/" target = "_blank">read the preprint!</a></p>
                        </div>
                        <div class = "picture" id = "right">
                            <video height = "250" autoplay loop>
                                <source src = "./resources/videos/SF_short_cropped.mp4" type = "video/mp4">
                                    Your broswer does not support this video :(
                            </video>
                        </div>
                    </div>

                    <span id = "title"><b>Detection of Familiar Faces at RSVP Rates</b></span>
                    <div class = "project">
                        <div class = "picture">
                                    <video height = "250" autoplay loop>
                                        <source src = "./resources/videos/RSVP_demo_cropped.mp4" type="video/mp4">
                                            Your browser does not support this video :(
                                    </video>
                                </div>
                        <div class = "description" id = "right">
                            <p>When channel surfing or walking about on campus, a familiar face elicits a feeling of quick, facile recognition, aided by the predictability of who we might encounter at that time and venue. 
                                Although the subjective impression is one of immediate and automatic recognition independent of context, to what extent is this true? 
                                To address this question I designed an experiment with taxing temporal limitations (presentation times of 133-168 msec/face) and maximum uncertainty (the identity of the target was not known). 
                                Neurotypical subjects averaged about 75% overall accuracy in detecting the presence of a celebrity. 
                                Not only this, but accurate detection&#8211indicating that a celebrity was present in the sequence&#8211was nearly always accompanied by identification of the target. 
                                Such successful detection and identification under demanding conditions indicates a remarkable facility of face recognition for neurotypical individuals. 
                                Prosopagnosics, those who struggle with face recognition, were significantly worse, with some performing at chance. 
                                They too, however, almost always were able to identify any celebrity that they detected, demonstrating that when we sense that a face is familiar, we almost always know who it is (although we sometimes block on the name).</p>
                            <p><a href = "./resources/videos/RSVPdemo_faster.mp4" target = "_blank">Watch a demo of the task</a> or <a href = "./resources/downloadable_files/RSVPDoppelganger_VSS_17.pdf" target = "_blank">check out the poster</a> or <a href = "./resources/downloadable_files/Hacker et al. - 2019 - A face in a (temporal) crowd.pdf" target = "_blank">read the paper!</a></p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- FOOTER -->
            <div class = "footer">
                    <span id = "lastModified">Last Modified: July 2025</span>
                    <span id = "credit">Website created by Catrina M. Hacker</span>
            </div>
    </body>
</html>